{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, roc_auc_score\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom tensorflow.keras.callbacks import History \nimport xgboost as xgb\nfrom sklearn.metrics import accuracy_score\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-19T21:43:24.477051Z","iopub.execute_input":"2021-12-19T21:43:24.477318Z","iopub.status.idle":"2021-12-19T21:43:24.490866Z","shell.execute_reply.started":"2021-12-19T21:43:24.477289Z","shell.execute_reply":"2021-12-19T21:43:24.490189Z"},"trusted":true},"execution_count":464,"outputs":[]},{"cell_type":"markdown","source":"What factors decide the grades of students? What combinations of them? Can we predict them?","metadata":{}},{"cell_type":"code","source":"mat = pd.read_csv(\"../input/student-alcohol-consumption/student-mat.csv\")\npor = pd.read_csv(\"../input/student-alcohol-consumption/student-por.csv\")\n#matpor = pd.merge(mat,por, on=(\"school\",\"sex\",\"age\",\"address\",\"famsize\",\"Pstatus\",\"Medu\",\"Fedu\",\"Mjob\",\"Fjob\",\"reason\",\"nursery\",\"internet\"))\nmatANDpor = pd.concat([mat,por]).drop_duplicates(subset=(\"school\",\"sex\",\"age\",\"address\",\"famsize\",\"Pstatus\",\"Medu\",\"Fedu\",\"Mjob\",\"Fjob\",\"reason\",\"nursery\",\"internet\"))","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:40:32.898874Z","iopub.execute_input":"2021-12-19T21:40:32.899763Z","iopub.status.idle":"2021-12-19T21:40:32.936191Z","shell.execute_reply.started":"2021-12-19T21:40:32.899723Z","shell.execute_reply":"2021-12-19T21:40:32.935539Z"},"trusted":true},"execution_count":441,"outputs":[]},{"cell_type":"markdown","source":"Lets plot the grade distributions for all binary variables to see if there is any resolving potential there","metadata":{}},{"cell_type":"code","source":"# Visualise grade distributions based on the binary discriminants\n\ndef plots(subject, period):\n    df = subject\n    subject_list = []\n    counter = -1\n    for i in df.keys():\n        if len(pd.unique(df[[i]].values.ravel('K'))) == 2:\n            subject_list.append(i)\n    half = int(np.ceil(len(subject_list)/2))\n    fig, ax = plt.subplots(half,2)\n    fig.set_size_inches(15, 25)\n    for a in subject_list:\n        counter += 1\n        if counter < half:\n            j = 0\n            k = 0\n        else:\n            j = 1\n            k = half\n        df1 = df[df[a] == pd.unique(df[[a]].values.ravel('K'))[0]]\n        df2 = df[df[a] == pd.unique(df[[a]].values.ravel('K'))[1]]\n        ax[counter-k][j].hist(df1[period], bins=20, alpha=0.5, label=pd.unique(df[[a]].values.ravel('K'))[0])\n        ax[counter-k][j].hist(df2[period], bins=20, alpha=0.5, label=pd.unique(df[[a]].values.ravel('K'))[1])\n        ax[counter-k][j].set_title(a)\n        ax[counter-k][j].legend()\n\nplots(matANDpor, \"G3\")\n\n# We can see some skew in some distributions as expected, although the relative sizes of data are\n# often very different","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:40:32.937358Z","iopub.execute_input":"2021-12-19T21:40:32.937601Z","iopub.status.idle":"2021-12-19T21:40:37.928862Z","shell.execute_reply.started":"2021-12-19T21:40:32.937570Z","shell.execute_reply":"2021-12-19T21:40:37.927851Z"},"trusted":true},"execution_count":442,"outputs":[]},{"cell_type":"markdown","source":"We can take two routes from here - see if we there is any correlation between grades in different periods, or try to predict a grade in general based on the other variables. Lets take the second route.","metadata":{}},{"cell_type":"code","source":"# Separate grades and cobine into one column\ngrades = [\"G1\", \"G2\", \"G3\"]\ndf_list = []\nfor i in range(len(grades)):\n    df = matANDpor.copy()\n    a = 0\n    while a < len(grades):\n        if a != i:\n            df.drop(grades[a], axis=1, inplace=True)\n        a+=1\n    df.rename(columns={grades[i] : \"G\"}, inplace=True)\n    df_list.append(df)\ndf = pd.concat(df_list)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:40:37.931279Z","iopub.execute_input":"2021-12-19T21:40:37.931613Z","iopub.status.idle":"2021-12-19T21:40:37.951542Z","shell.execute_reply.started":"2021-12-19T21:40:37.931571Z","shell.execute_reply":"2021-12-19T21:40:37.950552Z"},"trusted":true},"execution_count":443,"outputs":[]},{"cell_type":"code","source":"# Prepare \"bad\" and \"good\" grade scores (less than 11 and more than 10) for binary classification\n\nx_0 = df[(df[\"G\"]<11)]\nx_1 = df[(df[\"G\"]>10)]\ny_0 = pd.DataFrame(np.zeros(x_0.shape[0]))\ny_1 = pd.DataFrame(np.ones(x_1.shape[0]))\n\ny = pd.concat([y_0,y_1])\ny.columns = [\"class\"]\nx = pd.concat([x_0,x_3])","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:40:37.953270Z","iopub.execute_input":"2021-12-19T21:40:37.953834Z","iopub.status.idle":"2021-12-19T21:40:37.969000Z","shell.execute_reply.started":"2021-12-19T21:40:37.953785Z","shell.execute_reply":"2021-12-19T21:40:37.968024Z"},"trusted":true},"execution_count":444,"outputs":[]},{"cell_type":"code","source":"# Replace binary string options to 0 or 1\n\ndef binarize(df):\n    for i in df.keys():\n        if len(pd.unique(df[[i]].values.ravel('K'))) == 2:\n            df[i].replace({pd.unique(df[[i]].values.ravel('K'))[1] : 1,pd.unique(df[[i]].values.ravel('K'))[0] : 0},inplace=True)\n\nbinarize(x)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:40:37.971682Z","iopub.execute_input":"2021-12-19T21:40:37.972435Z","iopub.status.idle":"2021-12-19T21:40:38.054842Z","shell.execute_reply.started":"2021-12-19T21:40:37.972389Z","shell.execute_reply":"2021-12-19T21:40:38.053905Z"},"trusted":true},"execution_count":445,"outputs":[]},{"cell_type":"code","source":"# Drop nominal columns - these are harder to deal with and theres only four of them. Drop the grades \n# as well\n\nx = x.drop([\"Mjob\",\"Fjob\", \"reason\", \"guardian\", \"G\"], axis=1).reset_index(drop=True) \n\n# recale variables so that they go between 0-1 \nscaler_x = MinMaxScaler()\nscaler_y = MinMaxScaler()\nprint(scaler_x.fit(x))\nxscale=scaler_x.transform(x)\n\nx = pd.DataFrame(xscale,columns=x.columns)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:40:38.056056Z","iopub.execute_input":"2021-12-19T21:40:38.056300Z","iopub.status.idle":"2021-12-19T21:40:38.068980Z","shell.execute_reply.started":"2021-12-19T21:40:38.056271Z","shell.execute_reply":"2021-12-19T21:40:38.067854Z"},"trusted":true},"execution_count":446,"outputs":[]},{"cell_type":"code","source":"# split X1, X2, and y into train and validation dataset \n\nx_train, x_test, y_train, y_test  = train_test_split(\n    x,\n    y,\n    test_size=0.2,\n    random_state=123456,\n    stratify=y.values,\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:40:38.070415Z","iopub.execute_input":"2021-12-19T21:40:38.070836Z","iopub.status.idle":"2021-12-19T21:40:38.090716Z","shell.execute_reply.started":"2021-12-19T21:40:38.070791Z","shell.execute_reply":"2021-12-19T21:40:38.090015Z"},"trusted":true},"execution_count":447,"outputs":[]},{"cell_type":"code","source":"# define a simple NN\ndef baseline_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(len(x.columns), input_dim=len(x.columns), kernel_initializer='normal', activation='relu'))\n    model.add(Dense((len(x.columns))*2, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(1, activation=\"sigmoid\"))\n    model.compile(loss='binary_crossentropy', optimizer='adam')#, metrics=['accuracy'])  \n    return model\n\n# define early stopping\nearly_stop = EarlyStopping(monitor='val_loss',patience=10)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:40:38.092661Z","iopub.execute_input":"2021-12-19T21:40:38.093242Z","iopub.status.idle":"2021-12-19T21:40:38.101335Z","shell.execute_reply.started":"2021-12-19T21:40:38.093200Z","shell.execute_reply":"2021-12-19T21:40:38.100707Z"},"trusted":true},"execution_count":448,"outputs":[]},{"cell_type":"code","source":"history = History()\n\nmodel = baseline_model()\n\nmodel.fit(x_train, y_train,\n          #sample_weight=w_train,\n          batch_size=100,\n          epochs=100,\n          callbacks=[history,early_stop],\n          validation_data=(x_test, y_test))#, w_val))","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:40:38.103866Z","iopub.execute_input":"2021-12-19T21:40:38.104102Z","iopub.status.idle":"2021-12-19T21:40:42.389162Z","shell.execute_reply.started":"2021-12-19T21:40:38.104073Z","shell.execute_reply":"2021-12-19T21:40:42.388551Z"},"trusted":true},"execution_count":449,"outputs":[]},{"cell_type":"code","source":"# Extract number of run epochs from the training history\nepochs = range(1, len(history.history[\"loss\"])+1)\n\n# Extract loss on training and validation ddataset and plot them together\nplt.plot(epochs, history.history[\"loss\"], \"o-\", label=\"Training\")\nplt.plot(epochs, history.history[\"val_loss\"], \"o-\", label=\"Test\")\nplt.xlabel(\"Epochs\"), plt.ylabel(\"Loss\")\nplt.yscale(\"log\")\nplt.legend();","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:40:42.390211Z","iopub.execute_input":"2021-12-19T21:40:42.390604Z","iopub.status.idle":"2021-12-19T21:40:42.866363Z","shell.execute_reply.started":"2021-12-19T21:40:42.390570Z","shell.execute_reply":"2021-12-19T21:40:42.865551Z"},"trusted":true},"execution_count":450,"outputs":[]},{"cell_type":"code","source":"prediction = model.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:40:42.867566Z","iopub.execute_input":"2021-12-19T21:40:42.867788Z","iopub.status.idle":"2021-12-19T21:40:42.991636Z","shell.execute_reply.started":"2021-12-19T21:40:42.867761Z","shell.execute_reply":"2021-12-19T21:40:42.990865Z"},"trusted":true},"execution_count":451,"outputs":[]},{"cell_type":"code","source":"#  define a function to plot the ROC curves - just makes the roc_curve look nicer than the default\ndef plot_roc_curve(fpr, tpr, auc):\n    fig, ax = plt.subplots()\n    ax.plot(fpr, tpr)\n    ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n    ax.grid()\n    ax.text(0.6, 0.3, 'ROC AUC Score: {:.3f}'.format(auc),\n            bbox=dict(boxstyle='square,pad=0.3', fc='white', ec='k'))\n    lims = [np.min([ax.get_xlim(), ax.get_ylim()]), np.max([ax.get_xlim(), ax.get_ylim()])]\n    ax.plot(lims, lims, 'k--')\n    ax.set_xlim(lims)\n    ax.set_ylim(lims)\n    plt.savefig('roc_rho_rho_NN')","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:40:42.993205Z","iopub.execute_input":"2021-12-19T21:40:42.993698Z","iopub.status.idle":"2021-12-19T21:40:43.002016Z","shell.execute_reply.started":"2021-12-19T21:40:42.993654Z","shell.execute_reply":"2021-12-19T21:40:43.001410Z"},"trusted":true},"execution_count":452,"outputs":[]},{"cell_type":"code","source":"# plot ROC curve for improved training\ny_proba = model.predict(x_test) # outputs two probabilties\nauc = roc_auc_score(y_test, y_proba)\nfpr, tpr, _ = roc_curve(y_test, y_proba)\nplot_roc_curve(fpr, tpr, auc)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:40:43.003303Z","iopub.execute_input":"2021-12-19T21:40:43.003765Z","iopub.status.idle":"2021-12-19T21:40:43.422605Z","shell.execute_reply.started":"2021-12-19T21:40:43.003723Z","shell.execute_reply":"2021-12-19T21:40:43.421668Z"},"trusted":true},"execution_count":453,"outputs":[]},{"cell_type":"markdown","source":"This is good predicting power, but lets try our luck with a BDT instead. Lets use more categories.","metadata":{}},{"cell_type":"code","source":"x_0 = df[(df[\"G\"]<11)]\nx_1 = df[(df[\"G\"]>10)]\ny_0 = pd.DataFrame(np.zeros(x_0.shape[0]))\ny_1 = pd.DataFrame(np.ones(x_1.shape[0]))\n\ny = pd.concat([y_0,y_1])\ny.columns = [\"class\"]\nx = pd.concat([x_0,x_1])","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:40:43.424141Z","iopub.execute_input":"2021-12-19T21:40:43.424372Z","iopub.status.idle":"2021-12-19T21:40:43.437500Z","shell.execute_reply.started":"2021-12-19T21:40:43.424345Z","shell.execute_reply":"2021-12-19T21:40:43.436552Z"},"trusted":true},"execution_count":454,"outputs":[]},{"cell_type":"code","source":"def binarize(df):\n    for i in df.keys():\n        if len(pd.unique(df[[i]].values.ravel('K'))) == 2:\n            df[i].replace({pd.unique(df[[i]].values.ravel('K'))[1] : 1,pd.unique(df[[i]].values.ravel('K'))[0] : 0},inplace=True)\n\nbinarize(x)\n\nx = x.drop([\"Mjob\",\"Fjob\", \"reason\", \"guardian\", \"G\"], axis=1).reset_index(drop=True) \n\nscaler_x = MinMaxScaler()\nscaler_y = MinMaxScaler()\nprint(scaler_x.fit(x))\nxscale=scaler_x.transform(x)\n\nx = pd.DataFrame(xscale,columns=x.columns)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:40:43.438642Z","iopub.execute_input":"2021-12-19T21:40:43.438870Z","iopub.status.idle":"2021-12-19T21:40:43.526238Z","shell.execute_reply.started":"2021-12-19T21:40:43.438841Z","shell.execute_reply":"2021-12-19T21:40:43.525395Z"},"trusted":true},"execution_count":455,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test  = train_test_split(\n    x,\n    y,\n    test_size=0.2,\n    random_state=123456,\n    stratify=y.values,\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:40:43.527378Z","iopub.execute_input":"2021-12-19T21:40:43.527622Z","iopub.status.idle":"2021-12-19T21:40:43.547205Z","shell.execute_reply.started":"2021-12-19T21:40:43.527592Z","shell.execute_reply":"2021-12-19T21:40:43.546535Z"},"trusted":true},"execution_count":456,"outputs":[]},{"cell_type":"code","source":"# define some XGBoost parameters, unspecified will be default\n# https://xgboost.readthedocs.io/en/latest////index.html\n# not optimised at all, just playing by ear\n\nxgb_params = {\n    \"objective\": \"binary:logistic\",\n    \"max_depth\": 5,\n    \"learning_rate\": 0.02,\n    \"silent\": 1,\n    \"n_estimators\": 1000,\n    \"subsample\": 0.9,\n    \"seed\": 123451,\n}","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:40:43.548435Z","iopub.execute_input":"2021-12-19T21:40:43.549232Z","iopub.status.idle":"2021-12-19T21:40:43.559508Z","shell.execute_reply.started":"2021-12-19T21:40:43.549180Z","shell.execute_reply":"2021-12-19T21:40:43.558813Z"},"trusted":true},"execution_count":457,"outputs":[]},{"cell_type":"code","source":"xgb_clf = xgb.XGBClassifier(**xgb_params)\nxgb_clf.fit(\n    x_train,\n    y_train,\n    early_stopping_rounds=200, \n    eval_set=[(x_train, y_train), (x_test, y_test)],\n    eval_metric = \"auc\",\n    verbose=True,\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:40:43.560805Z","iopub.execute_input":"2021-12-19T21:40:43.561200Z","iopub.status.idle":"2021-12-19T21:40:53.337240Z","shell.execute_reply.started":"2021-12-19T21:40:43.561170Z","shell.execute_reply":"2021-12-19T21:40:53.336344Z"},"trusted":true},"execution_count":458,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# look at feature importance\n# can use different metrics (weight or gain)\nxgb.plot_importance(xgb_clf, importance_type='weight')\nxgb.plot_importance(xgb_clf, importance_type='gain')","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:40:53.338586Z","iopub.execute_input":"2021-12-19T21:40:53.339358Z","iopub.status.idle":"2021-12-19T21:40:54.757994Z","shell.execute_reply.started":"2021-12-19T21:40:53.339309Z","shell.execute_reply":"2021-12-19T21:40:54.756997Z"},"trusted":true},"execution_count":459,"outputs":[]},{"cell_type":"markdown","source":"Weight ranks the variables to which the BDT are used the most often, whereas the gain shows which are the most indicative. Clearly failures and absences matter a lot.","metadata":{}},{"cell_type":"code","source":"def plot_roc_curve(fpr, tpr, auc):\n    fig, ax = plt.subplots()\n    ax.plot(fpr, tpr)\n    ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n    ax.grid()\n    ax.text(0.6, 0.3, 'ROC AUC Score: {:.3f}'.format(auc),\n            bbox=dict(boxstyle='square,pad=0.3', fc='white', ec='k'))\n    lims = [np.min([ax.get_xlim(), ax.get_ylim()]), np.max([ax.get_xlim(), ax.get_ylim()])]\n    ax.plot(lims, lims, 'k--')\n    ax.set_xlim(lims)\n    ax.set_ylim(lims)\n    plt.savefig('roc_rho_rho')","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:40:54.759175Z","iopub.execute_input":"2021-12-19T21:40:54.759462Z","iopub.status.idle":"2021-12-19T21:40:54.768096Z","shell.execute_reply.started":"2021-12-19T21:40:54.759422Z","shell.execute_reply":"2021-12-19T21:40:54.767176Z"},"trusted":true},"execution_count":460,"outputs":[]},{"cell_type":"code","source":"y_proba = xgb_clf.predict_proba(x_test)\nauc = roc_auc_score(y_test, y_proba[:,1])\nfpr, tpr, _ = roc_curve(y_test, y_proba[:,1])\nplot_roc_curve(fpr, tpr, auc)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:42:19.114851Z","iopub.execute_input":"2021-12-19T21:42:19.115733Z","iopub.status.idle":"2021-12-19T21:42:19.460050Z","shell.execute_reply.started":"2021-12-19T21:42:19.115678Z","shell.execute_reply":"2021-12-19T21:42:19.459256Z"},"trusted":true},"execution_count":462,"outputs":[]},{"cell_type":"code","source":"y_proba = xgb_clf.predict_proba(x_test)\nidx = y_proba.argmax(axis=1)\ny_pred = (idx[:,None] == np.arange(y_proba.shape[1])).astype(float)\nflatpred = np.argmax(y_pred, axis=-1)\nflattest = np.argmax(y_test, axis=-1)\nflattest = flattest[\"class\"].tolist()\n#print(accuracy_score(y_test, y_pred), \" Convolutional Model\")","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:43:48.860866Z","iopub.execute_input":"2021-12-19T21:43:48.861168Z","iopub.status.idle":"2021-12-19T21:43:48.880796Z","shell.execute_reply.started":"2021-12-19T21:43:48.861134Z","shell.execute_reply":"2021-12-19T21:43:48.880045Z"},"trusted":true},"execution_count":466,"outputs":[]},{"cell_type":"code","source":"#~~ Creating confusion arrays ~~#\ntruelabels = np.array([[0,0],[0,0]]) #for true modes 0,1,2,3\nlengthstrue = [0,0]\nlengthspred = [0,0]\nfor a in range(len(flattest)):\n    truelabels[int(flattest[a])][int(flatpred[a])] +=1\n    lengthstrue[int(flattest[a])] +=1\n    lengthspred[int(flatpred[a])] +=1\ntruelabelpurity = truelabels/lengthspred\ntruelabelefficiency = np.array([[0,0],[0,0]], dtype = float)\nfor a in range(2):\n    for b in range(2):\n        truelabelefficiency[a][b] = truelabels[a][b]/lengthstrue[a]","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:43:52.060291Z","iopub.execute_input":"2021-12-19T21:43:52.060767Z","iopub.status.idle":"2021-12-19T21:43:52.070891Z","shell.execute_reply.started":"2021-12-19T21:43:52.060715Z","shell.execute_reply":"2021-12-19T21:43:52.070053Z"},"trusted":true},"execution_count":467,"outputs":[]},{"cell_type":"code","source":"#~~ PLOTTING CONFUSION MATRICES ~~#\nplt.rcParams.update({'figure.autolayout': True})\nlabellist = ['Bad', 'Good']\nfig, ax = plt.subplots(1,2)\nplt.tight_layout()\nfig.set_size_inches(12, 8)\n\nax[0].imshow(truelabelefficiency, cmap = 'Blues')\nfor i in range(2):\n    for j in range(2):\n        if truelabelefficiency[i, j] > 0.5:\n            text = ax[0].text(j, i, round(truelabelefficiency[i, j], 3),\n                           ha=\"center\", va=\"center\", color=\"w\")\n        else:\n            text = ax[0].text(j, i, round(truelabelefficiency[i, j], 3),\n                           ha=\"center\", va=\"center\", color=\"black\")\n\n        \nax[0].set_title('Efficiency')\nax[0].set_xticks([0,1])\nax[0].set_yticks([0,1])\nax[0].set_xticklabels(labellist)\nax[0].set_yticklabels(labellist)\nax[0].set_xlabel('Predicted Mode')\nax[0].set_ylabel('True Mode')\n\n\nax[1].imshow(truelabelpurity, cmap = 'Blues')\nfor i in range(2):\n    for j in range(2):\n        if truelabelpurity[i, j] > 0.5:\n            text = ax[1].text(j, i, round(truelabelpurity[i, j], 3),\n                           ha=\"center\", va=\"center\", color=\"w\")\n        else:\n            text = ax[1].text(j, i, round(truelabelpurity[i, j], 3),\n                           ha=\"center\", va=\"center\", color=\"black\")\n\nax[1].set_title('Purity')\nax[1].set_xticks([0,1])\nax[1].set_yticks([0,1])\nax[1].set_xticklabels(labellist)\nax[1].set_yticklabels(labellist)\nax[1].set_xlabel('Predicted Grade')\nax[1].set_ylabel('True Grade')","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:43:54.457976Z","iopub.execute_input":"2021-12-19T21:43:54.458726Z","iopub.status.idle":"2021-12-19T21:43:54.884128Z","shell.execute_reply.started":"2021-12-19T21:43:54.458673Z","shell.execute_reply":"2021-12-19T21:43:54.883517Z"},"trusted":true},"execution_count":468,"outputs":[]},{"cell_type":"markdown","source":"Now lets try with mor categories.","metadata":{}},{"cell_type":"code","source":"x_0 = df[(df[\"G\"]<11)]\nx_1 = df[(df[\"G\"]>4) & (df[\"G\"]<11)]\nx_2 = df[(df[\"G\"]>10) & (df[\"G\"]<16)]\nx_3 = df[(df[\"G\"]>10)]\ny_0 = pd.DataFrame(np.zeros(x_0.shape[0]))\ny_1 = pd.DataFrame(np.ones(x_1.shape[0]))\ny_2 = pd.DataFrame(2*np.ones(x_2.shape[0]))\ny_3 = pd.DataFrame(3*np.ones(x_3.shape[0]))\n\ny = pd.concat([y_0,y_1,y_2,y_3])\ny.columns = [\"class\"]\nx = pd.concat([x_0,x_1,x_2,x_3])\n\ndef binarize(df):\n    for i in df.keys():\n        if len(pd.unique(df[[i]].values.ravel('K'))) == 2:\n            df[i].replace({pd.unique(df[[i]].values.ravel('K'))[1] : 1,pd.unique(df[[i]].values.ravel('K'))[0] : 0},inplace=True)\n\nbinarize(x)\n\nx = x.drop([\"Mjob\",\"Fjob\", \"reason\", \"guardian\", \"G\"], axis=1).reset_index(drop=True) \n\nscaler_x = MinMaxScaler()\nscaler_y = MinMaxScaler()\nprint(scaler_x.fit(x))\nxscale=scaler_x.transform(x)\n\nx = pd.DataFrame(xscale,columns=x.columns)\n\nx_train, x_test, y_train, y_test  = train_test_split(\n    x,\n    y,\n    test_size=0.2,\n    random_state=123456,\n    stratify=y.values,\n)\n\nxgb_params = {\n    \"objective\": \"multi:softprob\",\n    \"max_depth\": 5,\n    \"learning_rate\": 0.02,\n    \"silent\": 1,\n    \"n_estimators\": 1000,\n    \"subsample\": 0.9,\n    \"seed\": 123451,\n}\n\nxgb_clf = xgb.XGBClassifier(**xgb_params)\nxgb_clf.fit(\n    x_train,\n    y_train,\n    early_stopping_rounds=200, \n    eval_set=[(x_train, y_train), (x_test, y_test)],\n    eval_metric = \"auc\",\n    verbose=True,\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:44:05.680376Z","iopub.execute_input":"2021-12-19T21:44:05.680686Z","iopub.status.idle":"2021-12-19T21:44:16.459703Z","shell.execute_reply.started":"2021-12-19T21:44:05.680651Z","shell.execute_reply":"2021-12-19T21:44:16.458784Z"},"trusted":true},"execution_count":469,"outputs":[]},{"cell_type":"code","source":"xgb.plot_importance(xgb_clf, importance_type='weight')\nxgb.plot_importance(xgb_clf, importance_type='gain')","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:44:18.902159Z","iopub.execute_input":"2021-12-19T21:44:18.902772Z","iopub.status.idle":"2021-12-19T21:44:20.320289Z","shell.execute_reply.started":"2021-12-19T21:44:18.902740Z","shell.execute_reply":"2021-12-19T21:44:20.319495Z"},"trusted":true},"execution_count":470,"outputs":[]},{"cell_type":"code","source":"y_proba = xgb_clf.predict_proba(x_test)\nauc = roc_auc_score(y_test, y_proba[:,1], multi_class=\"ovr\",average=None)\nfpr, tpr, _ = roc_curve(y_test, y_proba[:,1])\nplot_roc_curve(fpr, tpr, auc)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:45:17.221197Z","iopub.execute_input":"2021-12-19T21:45:17.221507Z","iopub.status.idle":"2021-12-19T21:45:17.275672Z","shell.execute_reply.started":"2021-12-19T21:45:17.221453Z","shell.execute_reply":"2021-12-19T21:45:17.274411Z"},"trusted":true},"execution_count":475,"outputs":[]},{"cell_type":"code","source":"y_proba = xgb_clf.predict_proba(x_test)\nidx = y_proba.argmax(axis=1)\ny_pred = (idx[:,None] == np.arange(y_proba.shape[1])).astype(float)\nflatpred = np.argmax(y_pred, axis=-1)\nflattest = np.argmax(y_test, axis=-1)\nflattest = flattest[\"class\"].tolist()\nprint(accuracy_score(y_test, y_pred), \" Convolutional Model\")","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:44:32.649918Z","iopub.execute_input":"2021-12-19T21:44:32.650197Z","iopub.status.idle":"2021-12-19T21:44:32.700794Z","shell.execute_reply.started":"2021-12-19T21:44:32.650170Z","shell.execute_reply":"2021-12-19T21:44:32.699859Z"},"trusted":true},"execution_count":472,"outputs":[]},{"cell_type":"code","source":"#~~ Creating confusion arrays ~~#\ntruelabels = np.array([[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0]]) #for true modes 0,1,2,3\nlengthstrue = [0,0,0,0]\nlengthspred = [0,0,0,0]\nfor a in range(len(flattest)):\n    truelabels[int(flattest[a])][int(flatpred[a])] +=1\n    lengthstrue[int(flattest[a])] +=1\n    lengthspred[int(flatpred[a])] +=1\ntruelabelpurity = truelabels/lengthspred\ntruelabelefficiency = np.array([[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0]], dtype = float)\nfor a in range(4):\n    for b in range(4):\n        truelabelefficiency[a][b] = truelabels[a][b]/lengthstrue[a]","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:44:38.403104Z","iopub.execute_input":"2021-12-19T21:44:38.403675Z","iopub.status.idle":"2021-12-19T21:44:38.417974Z","shell.execute_reply.started":"2021-12-19T21:44:38.403625Z","shell.execute_reply":"2021-12-19T21:44:38.417115Z"},"trusted":true},"execution_count":473,"outputs":[]},{"cell_type":"code","source":"plt.rcParams.update({'figure.autolayout': True})\nlabellist = ['Very Bad', 'Bad', 'Good', 'Very Good']\nfig, ax = plt.subplots(1,2)\nplt.tight_layout()\nfig.set_size_inches(12, 8)\n\nax[0].imshow(truelabelefficiency, cmap = 'Blues')\nfor i in range(4):\n    for j in range(4):\n        if truelabelefficiency[i, j] > 0.5:\n            text = ax[0].text(j, i, round(truelabelefficiency[i, j], 3),\n                           ha=\"center\", va=\"center\", color=\"w\")\n        else:\n            text = ax[0].text(j, i, round(truelabelefficiency[i, j], 3),\n                           ha=\"center\", va=\"center\", color=\"black\")\n\n        \nax[0].set_title('Efficiency')\nax[0].set_xticks([0,1,2,3])\nax[0].set_yticks([0,1,2,3])\nax[0].set_xticklabels(labellist)\nax[0].set_yticklabels(labellist)\nax[0].set_xlabel('Predicted Mode')\nax[0].set_ylabel('True Mode')\n\n\nax[1].imshow(truelabelpurity, cmap = 'Blues')\nfor i in range(4):\n    for j in range(4):\n        if truelabelpurity[i, j] > 0.5:\n            text = ax[1].text(j, i, round(truelabelpurity[i, j], 3),\n                           ha=\"center\", va=\"center\", color=\"w\")\n        else:\n            text = ax[1].text(j, i, round(truelabelpurity[i, j], 3),\n                           ha=\"center\", va=\"center\", color=\"black\")\n\nax[1].set_title('Purity')\nax[1].set_xticks([0,1,2,3])\nax[1].set_yticks([0,1,2,3])\nax[1].set_xticklabels(labellist)\nax[1].set_yticklabels(labellist)\nax[1].set_xlabel('Predicted Grade')\nax[1].set_ylabel('True Grade')","metadata":{"execution":{"iopub.status.busy":"2021-12-19T21:44:40.750989Z","iopub.execute_input":"2021-12-19T21:44:40.751267Z","iopub.status.idle":"2021-12-19T21:44:41.292035Z","shell.execute_reply.started":"2021-12-19T21:44:40.751233Z","shell.execute_reply":"2021-12-19T21:44:41.291300Z"},"trusted":true},"execution_count":474,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}